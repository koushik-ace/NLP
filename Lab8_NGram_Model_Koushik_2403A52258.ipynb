{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAzxQaEESIiZqYvpiffQ55",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik-ace/NLP/blob/main/Lab8_NGram_Model_Koushik_2403A52258.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Corpus\n"
      ],
      "metadata": {
        "id": "dSvIvbk1PXQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aCFKa28ENX6k"
      },
      "outputs": [],
      "source": [
        "# Large Corpus with 10 Documents\n",
        "\n",
        "D1 = \"\"\"\n",
        "I am studying BTech in Computer Science at SR University.\n",
        "My academic journey started with interest in mathematics and physics.\n",
        "I learned programming using C, C++, and Python.\n",
        "Data structures and algorithms improved my problem-solving skills.\n",
        "\"\"\"\n",
        "\n",
        "D2 = \"\"\"\n",
        "During my second year, I studied operating systems and database management systems.\n",
        "I learned SQL queries, indexing, normalization, and transaction management.\n",
        "Process scheduling and memory allocation were important topics.\n",
        "\"\"\"\n",
        "\n",
        "D3 = \"\"\"\n",
        "Machine learning became my favorite subject.\n",
        "I studied regression, classification, clustering, and neural networks.\n",
        "I implemented projects using Scikit-learn and TensorFlow.\n",
        "Deep learning models improved prediction accuracy.\n",
        "\"\"\"\n",
        "\n",
        "D4 = \"\"\"\n",
        "Cybersecurity is an important domain in computer science.\n",
        "I studied cryptography, encryption algorithms, and ethical hacking.\n",
        "Network security and malware analysis were explored.\n",
        "Digital forensics was introduced in laboratory sessions.\n",
        "\"\"\"\n",
        "\n",
        "D5 = \"\"\"\n",
        "Cloud computing enables scalable software systems.\n",
        "I learned Amazon Web Services, Microsoft Azure, and Google Cloud Platform.\n",
        "Docker and Kubernetes improved deployment efficiency.\n",
        "Virtual machines support distributed infrastructure.\n",
        "\"\"\"\n",
        "\n",
        "D6 = \"\"\"\n",
        "Software engineering focuses on quality development.\n",
        "I studied SDLC, agile methodology, and DevOps practices.\n",
        "Git and GitHub improved collaboration.\n",
        "CI/CD pipelines automated testing and deployment.\n",
        "\"\"\"\n",
        "\n",
        "D7 = \"\"\"\n",
        "Web development is essential for modern applications.\n",
        "I learned HTML, CSS, JavaScript, and React framework.\n",
        "Backend development used Flask and Django.\n",
        "RESTful APIs enabled data communication.\n",
        "\"\"\"\n",
        "\n",
        "D8 = \"\"\"\n",
        "Data science involves data analysis and visualization.\n",
        "I used Pandas, NumPy, and Matplotlib libraries.\n",
        "Exploratory data analysis improved decision making.\n",
        "Statistical modeling enhanced insights.\n",
        "\"\"\"\n",
        "\n",
        "D9 = \"\"\"\n",
        "Artificial intelligence includes natural language processing.\n",
        "I studied sentiment analysis and chatbot development.\n",
        "Recommendation systems improved user experience.\n",
        "Speech recognition was implemented using Python.\n",
        "\"\"\"\n",
        "\n",
        "D10 = \"\"\"\n",
        "My career goal is to become a software engineer.\n",
        "I aim to work on intelligent systems and distributed computing.\n",
        "Continuous learning through certifications is important.\n",
        "Innovation and creativity drive technological growth.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all documents\n",
        "\n",
        "combined_text = D1 + D2 + D3 + D4 + D5 + D6 + D7 + D8 + D9 + D10\n",
        "\n",
        "print(\"Total Words:\", len(combined_text.split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGt41aDbPfAa",
        "outputId": "236766a6-3614-4c8c-b4cd-227752493507"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Words: 280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "Iv72bhUZQAuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import collections\n",
        "\n",
        "# Lowercase\n",
        "text = combined_text.lower()\n",
        "\n",
        "# Remove punctuation\n",
        "text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "# Tokenization\n",
        "words = text.split()\n",
        "\n",
        "print(\"First 30 Tokens:\")\n",
        "print(words[:30])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lkbm8OTPj5N",
        "outputId": "31d7a9a4-34d4-4493-a1db-78aca747b2ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 30 Tokens:\n",
            "['i', 'am', 'studying', 'btech', 'in', 'computer', 'science', 'at', 'sr', 'university', 'my', 'academic', 'journey', 'started', 'with', 'interest', 'in', 'mathematics', 'and', 'physics', 'i', 'learned', 'programming', 'using', 'c', 'c', 'and', 'python', 'data', 'structures']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##dentify Rare Words & Add UNK"
      ],
      "metadata": {
        "id": "70PkL5PhXP3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify Rare Words (Frequency = 1)\n",
        "\n",
        "word_freq = collections.Counter(words)\n",
        "\n",
        "rare_words = []\n",
        "\n",
        "for word, count in word_freq.items():\n",
        "    if count == 1:\n",
        "        rare_words.append(word)\n",
        "\n",
        "print(\"Number of Rare Words:\", len(rare_words))\n",
        "\n",
        "\n",
        "# Replace rare words with UNK\n",
        "\n",
        "words_unk = []\n",
        "\n",
        "for word in words:\n",
        "    if word_freq[word] == 1:\n",
        "        words_unk.append(\"UNK\")\n",
        "    else:\n",
        "        words_unk.append(word)\n",
        "\n",
        "\n",
        "print(\"Sample After UNK Replacement:\")\n",
        "print(words_unk[:30])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z7HFf_uXOU1",
        "outputId": "a913bec4-0901-45e6-c6bb-a081fea9b79e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Rare Words: 152\n",
            "Sample After UNK Replacement:\n",
            "['i', 'UNK', 'UNK', 'UNK', 'in', 'computer', 'science', 'UNK', 'UNK', 'UNK', 'my', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'in', 'UNK', 'and', 'UNK', 'i', 'learned', 'UNK', 'using', 'c', 'c', 'and', 'python', 'data', 'UNK']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Rebuild N-Gram Models with UNK"
      ],
      "metadata": {
        "id": "uBjGKomxXUfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build N-grams with UNK\n",
        "\n",
        "# Unigrams\n",
        "unigram_unk = collections.Counter(words_unk)\n",
        "\n",
        "# Bigrams\n",
        "bigrams_unk = []\n",
        "\n",
        "for i in range(len(words_unk)-1):\n",
        "    bigrams_unk.append((words_unk[i], words_unk[i+1]))\n",
        "\n",
        "bigram_unk = collections.Counter(bigrams_unk)\n",
        "\n",
        "\n",
        "# Trigrams\n",
        "trigrams_unk = []\n",
        "\n",
        "for i in range(len(words_unk)-2):\n",
        "    trigrams_unk.append((words_unk[i], words_unk[i+1], words_unk[i+2]))\n",
        "\n",
        "trigram_unk = collections.Counter(trigrams_unk)\n"
      ],
      "metadata": {
        "id": "fpvgNmf0XYzy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def unigram_probability(word, freq, total, V, k=0):\n",
        "\n",
        "    return (freq.get(word,0)+k)/(total + k*V)\n"
      ],
      "metadata": {
        "id": "a9quT7m1Xbg4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_probability(sentence, freq, k=0):\n",
        "\n",
        "    sent = sentence.lower().split()\n",
        "\n",
        "    prob = 1\n",
        "\n",
        "    for word in sent:\n",
        "        p = unigram_probability(word, freq, len(words), V, k)\n",
        "        prob *= p\n",
        "\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "2WvndcyEXeoL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perplexity Function"
      ],
      "metadata": {
        "id": "pjZMZgi5XjfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, freq, k=0):\n",
        "\n",
        "    sent = sentence.lower().split()\n",
        "\n",
        "    log_prob = 0\n",
        "    n = len(sent)\n",
        "\n",
        "    for word in sent:\n",
        "\n",
        "        p = unigram_probability(word, freq, len(words), V, k)\n",
        "\n",
        "        if p > 0:\n",
        "            log_prob += math.log(p)\n",
        "\n",
        "    perp = math.exp(-log_prob/n)\n",
        "\n",
        "    return perp\n"
      ],
      "metadata": {
        "id": "5gzua8G0XiYr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unigram Counts"
      ],
      "metadata": {
        "id": "yDLRb8CUQHVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram counts\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Top 20 Unigrams:\\n\")\n",
        "\n",
        "for word, count in unigram_counts.most_common(20):\n",
        "    print(word, \":\", count)\n",
        "\n",
        "# Vocabulary Size\n",
        "V = len(unigram_counts)\n",
        "print(\"\\nVocabulary Size =\", V)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijc1uyeOQJOc",
        "outputId": "db60de56-3893-4d3a-9e40-e4b67c27ba44"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 Unigrams:\n",
            "\n",
            "and : 22\n",
            "i : 13\n",
            "improved : 6\n",
            "my : 5\n",
            "data : 5\n",
            "studied : 5\n",
            "systems : 5\n",
            "in : 4\n",
            "learned : 4\n",
            "is : 4\n",
            "analysis : 4\n",
            "development : 4\n",
            "science : 3\n",
            "using : 3\n",
            "important : 3\n",
            "learning : 3\n",
            "software : 3\n",
            "computer : 2\n",
            "c : 2\n",
            "python : 2\n",
            "\n",
            "Vocabulary Size = 185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compare Perplexity (Before & After UNK)"
      ],
      "metadata": {
        "id": "WSDDxVyrYJdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"machine learning improves prediction accuracy\"\n",
        "\n",
        "print(\"Sentence:\", test_sentence)\n",
        "\n",
        "print(\"\\n--- Without UNK ---\")\n",
        "print(\"Perplexity:\", perplexity(test_sentence, unigram_counts))\n",
        "\n",
        "print(\"\\n--- With UNK ---\")\n",
        "print(\"Perplexity:\", perplexity(test_sentence, unigram_unk))\n",
        "\n",
        "print(\"\\n--- With Add-One Smoothing ---\")\n",
        "print(\"Perplexity:\", perplexity(test_sentence, unigram_counts, k=1))\n",
        "\n",
        "print(\"\\n--- With Add-K (0.5) Smoothing ---\")\n",
        "print(\"Perplexity:\", perplexity(test_sentence, unigram_counts, k=0.5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlBUrtcQXnC9",
        "outputId": "08f24235-71c0-4eb7-b42f-e3eb4e24d5fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: machine learning improves prediction accuracy\n",
            "\n",
            "--- Without UNK ---\n",
            "Perplexity: 72.82863565721485\n",
            "\n",
            "--- With UNK ---\n",
            "Perplexity: 2.4774640162541157\n",
            "\n",
            "--- With Add-One Smoothing ---\n",
            "Perplexity: 232.50000000000009\n",
            "\n",
            "--- With Add-K (0.5) Smoothing ---\n",
            "Perplexity: 261.13429503799154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy Perplexity Calculator\n",
        "\n",
        "sentence = input(\"Enter a sentence: \")\n",
        "\n",
        "print(\"\\nWithout UNK:\", perplexity(sentence, unigram_counts))\n",
        "print(\"With UNK:\", perplexity(sentence, unigram_unk))\n",
        "print(\"Add-One:\", perplexity(sentence, unigram_counts,1))\n",
        "print(\"Add-K:\", perplexity(sentence, unigram_counts,0.5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmoey7kJXquw",
        "outputId": "62f2de62-9635-49c8-93aa-1d5ad7e3650a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: i\n",
            "\n",
            "Without UNK: 21.53846153846154\n",
            "With UNK: 21.53846153846154\n",
            "Add-One: 33.21428571428571\n",
            "Add-K: 27.592592592592595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bigram counts"
      ],
      "metadata": {
        "id": "Dqgv_fkfQM1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Bigrams\n",
        "\n",
        "bigrams = []\n",
        "\n",
        "for i in range(len(words)-1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"Top 15 Bigrams:\\n\")\n",
        "\n",
        "for bg, count in bigram_counts.most_common(15):\n",
        "    print(bg[0], bg[1], \":\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDU2DcSoQMgx",
        "outputId": "abd0705d-9e12-4746-fd94-6100d75f4d48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 Bigrams:\n",
            "\n",
            "i studied : 5\n",
            "i learned : 4\n",
            "in computer : 2\n",
            "computer science : 2\n",
            "systems and : 2\n",
            "systems i : 2\n",
            "data analysis : 2\n",
            "analysis and : 2\n",
            "i am : 1\n",
            "am studying : 1\n",
            "studying btech : 1\n",
            "btech in : 1\n",
            "science at : 1\n",
            "at sr : 1\n",
            "sr university : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trigram count"
      ],
      "metadata": {
        "id": "OY2NAPKHQUIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Trigrams\n",
        "\n",
        "trigrams = []\n",
        "\n",
        "for i in range(len(words)-2):\n",
        "    trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "trigram_counts = collections.Counter(trigrams)\n",
        "\n",
        "print(\"Top 15 Trigrams:\\n\")\n",
        "\n",
        "for tg, count in trigram_counts.most_common(15):\n",
        "    print(tg[0], tg[1], tg[2], \":\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG5IQJuyQXzO",
        "outputId": "800f9c26-c555-4102-d80d-b9683e9803f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 Trigrams:\n",
            "\n",
            "in computer science : 2\n",
            "systems i learned : 2\n",
            "i am studying : 1\n",
            "am studying btech : 1\n",
            "studying btech in : 1\n",
            "btech in computer : 1\n",
            "computer science at : 1\n",
            "science at sr : 1\n",
            "at sr university : 1\n",
            "sr university my : 1\n",
            "university my academic : 1\n",
            "my academic journey : 1\n",
            "academic journey started : 1\n",
            "journey started with : 1\n",
            "started with interest : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bigram Prediction"
      ],
      "metadata": {
        "id": "2li9LwEwQab0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_bigram(sequence):\n",
        "\n",
        "    seq = sequence.lower().split()\n",
        "\n",
        "    if not seq:\n",
        "        return \"Enter valid input\"\n",
        "\n",
        "    last = seq[-1]\n",
        "\n",
        "    candidates = {}\n",
        "\n",
        "    for (w1,w2),count in bigram_counts.items():\n",
        "        if w1 == last:\n",
        "            candidates[w2] = count\n",
        "\n",
        "    if not candidates:\n",
        "        return \"No prediction available\"\n",
        "\n",
        "    total = unigram_counts.get(last,0)\n",
        "\n",
        "    best = None\n",
        "    best_prob = 0\n",
        "\n",
        "    for w,c in candidates.items():\n",
        "\n",
        "        prob = c/total\n",
        "        print(\"Probability of\",w,\"=\",prob)\n",
        "\n",
        "        if prob>best_prob:\n",
        "            best_prob = prob\n",
        "            best = w\n",
        "\n",
        "    return best\n"
      ],
      "metadata": {
        "id": "IHDMdAZ4QaBq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deploy Bigram Model (Without Smoothing)"
      ],
      "metadata": {
        "id": "G2gKa_0UTogt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy Bigram Model\n",
        "\n",
        "ip_text = input(\"Enter text: \")\n",
        "\n",
        "result = predict_bigram(ip_text)\n",
        "\n",
        "print(\"Predicted Next Word:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_rLpZeFTnAl",
        "outputId": "979b74f2-fb11-47ab-e985-b8d1403f4b7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: hello\n",
            "Predicted Next Word: No prediction available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_bigram(\"machine\"))\n",
        "print(predict_bigram(\"software\"))\n",
        "print(predict_bigram(\"cloud\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdV2GICnQmYz",
        "outputId": "9dd97399-e9bb-4ba2-a40c-2c4ed853ba02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of learning = 1.0\n",
            "learning\n",
            "Probability of systems = 0.3333333333333333\n",
            "Probability of engineering = 0.3333333333333333\n",
            "Probability of engineer = 0.3333333333333333\n",
            "systems\n",
            "Probability of computing = 0.5\n",
            "Probability of platform = 0.5\n",
            "computing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bigram with Laplace Smoothing"
      ],
      "metadata": {
        "id": "j5VKMelfQjxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_bigram_laplace(sequence):\n",
        "\n",
        "    seq = sequence.lower().split()\n",
        "\n",
        "    if not seq:\n",
        "        return \"Enter valid input\"\n",
        "\n",
        "    last = seq[-1]\n",
        "\n",
        "    candidates = {}\n",
        "\n",
        "    for (w1,w2),count in bigram_counts.items():\n",
        "        if w1 == last:\n",
        "            candidates[w2] = count\n",
        "\n",
        "    if not candidates:\n",
        "        return \"No prediction available\"\n",
        "\n",
        "    total = unigram_counts.get(last,0)\n",
        "\n",
        "    best = None\n",
        "    best_prob = 0\n",
        "\n",
        "    for w,c in candidates.items():\n",
        "\n",
        "        prob = (c+1)/(total+V)\n",
        "        print(\"Probability of\",w,\"=\",prob)\n",
        "\n",
        "        if prob>best_prob:\n",
        "            best_prob = prob\n",
        "            best = w\n",
        "\n",
        "    return best\n"
      ],
      "metadata": {
        "id": "AUhgHtA4Qsg_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deploy Bigram + Laplace Smoothing"
      ],
      "metadata": {
        "id": "iDLq_GbGT3OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy Laplace Bigram Model\n",
        "\n",
        "ip_text = input(\"Enter text: \")\n",
        "\n",
        "result = predict_bigram_laplace(ip_text)\n",
        "\n",
        "print(\"Predicted Next Word (Laplace):\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW6eyqxUT2jm",
        "outputId": "49e31beb-aeec-4dea-d712-2d320bb679f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: is a\n",
            "Probability of software = 0.010752688172043012\n",
            "Predicted Next Word (Laplace): software\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Add-K Smoothing (K = 0.5)"
      ],
      "metadata": {
        "id": "rgxKyLx5Q2z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_bigram_k(sequence,k=0.5):\n",
        "\n",
        "    seq = sequence.lower().split()\n",
        "\n",
        "    if not seq:\n",
        "        return \"Enter valid input\"\n",
        "\n",
        "    last = seq[-1]\n",
        "\n",
        "    candidates = {}\n",
        "\n",
        "    for (w1,w2),count in bigram_counts.items():\n",
        "        if w1 == last:\n",
        "            candidates[w2] = count\n",
        "\n",
        "    if not candidates:\n",
        "        return \"No prediction available\"\n",
        "\n",
        "    total = unigram_counts.get(last,0)\n",
        "\n",
        "    best = None\n",
        "    best_prob = 0\n",
        "\n",
        "    for w,c in candidates.items():\n",
        "\n",
        "        prob = (c+k)/(total+k*V)\n",
        "        print(\"Probability of\",w,\"=\",prob)\n",
        "\n",
        "        if prob>best_prob:\n",
        "            best_prob = prob\n",
        "            best = w\n",
        "\n",
        "    return best\n"
      ],
      "metadata": {
        "id": "nOlAG8i5Q4KO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deploy Bigram + Add-K Smoothing"
      ],
      "metadata": {
        "id": "Sfrw5AsqUFb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy Add-K Bigram Model\n",
        "\n",
        "ip_text = input(\"Enter text: \")\n",
        "\n",
        "result = predict_bigram_k(ip_text, 0.5)\n",
        "\n",
        "print(\"Predicted Next Word (Add-K):\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_IKC00TUHbM",
        "outputId": "c9933e01-e061-456b-c4ec-9c712e950e6f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: i\n",
            "Probability of am = 0.014218009478672985\n",
            "Probability of learned = 0.04265402843601896\n",
            "Probability of studied = 0.052132701421800945\n",
            "Probability of implemented = 0.014218009478672985\n",
            "Probability of used = 0.014218009478672985\n",
            "Probability of aim = 0.014218009478672985\n",
            "Predicted Next Word (Add-K): studied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trigram Prediction"
      ],
      "metadata": {
        "id": "6TuCHYjGQ9RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_trigram(sequence):\n",
        "\n",
        "    seq = sequence.lower().split()\n",
        "\n",
        "    if len(seq)<2:\n",
        "        return \"Enter at least two words\"\n",
        "\n",
        "    last2 = tuple(seq[-2:])\n",
        "\n",
        "    candidates = {}\n",
        "\n",
        "    for (w1,w2,w3),count in trigram_counts.items():\n",
        "        if (w1,w2)==last2:\n",
        "            candidates[w3]=count\n",
        "\n",
        "    if not candidates:\n",
        "        return \"No prediction available\"\n",
        "\n",
        "    total = bigram_counts.get(last2,0)\n",
        "\n",
        "    best=None\n",
        "    best_prob=0\n",
        "\n",
        "    for w,c in candidates.items():\n",
        "\n",
        "        prob=c/total\n",
        "        print(\"Probability of\",w,\"=\",prob)\n",
        "\n",
        "        if prob>best_prob:\n",
        "            best_prob=prob\n",
        "            best=w\n",
        "\n",
        "    return best\n"
      ],
      "metadata": {
        "id": "IAaF4sFUQ-vh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deploy Trigram Model"
      ],
      "metadata": {
        "id": "LoQ0Al-SUTGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy Trigram Model\n",
        "\n",
        "ip_text = input(\"Enter two words: \")\n",
        "\n",
        "result = predict_trigram(ip_text)\n",
        "\n",
        "print(\"Predicted Next Word (Trigram):\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVWb_iNeURoc",
        "outputId": "f51c4c21-a75c-416b-d78c-79cde953632e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter two words: I learned \n",
            "Probability of programming = 0.25\n",
            "Probability of sql = 0.25\n",
            "Probability of amazon = 0.25\n",
            "Probability of html = 0.25\n",
            "Predicted Next Word (Trigram): programming\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_trigram(\"machine learning\"))\n",
        "print(predict_trigram(\"software engineering\"))\n",
        "print(predict_trigram(\"cloud computing\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcBNnhrVREWu",
        "outputId": "cbd58fa7-525d-4024-cf60-50251640efd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of became = 1.0\n",
            "became\n",
            "Probability of focuses = 1.0\n",
            "focuses\n",
            "Probability of enables = 1.0\n",
            "enables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Answers to Questions\n",
        "1. Why do unseen words cause zero probability?\n",
        "\n",
        "* Because they never appear in training data, their frequency is zero.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "2. What is UNK token?\n",
        "\n",
        "* UNK represents unknown or rare words.\n",
        "\n",
        "3. Which smoothing worked best?\n",
        "\n",
        "* Add-k smoothing (k = 0.5).\n",
        "\n",
        "4. Did perplexity improve? Why?\n",
        "\n",
        "* Yes, because smoothing and UNK remove zero probabilities."
      ],
      "metadata": {
        "id": "n5oQMhunRD3C"
      }
    }
  ]
}