{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONWh0oOgQZ0f4tkviwMu9Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik-ace/NLP/blob/main/Assingment_2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163e9d14"
      },
      "source": [
        "## Install and Import Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edd863f8",
        "outputId": "35b2eed8-86da-447c-de78-2a82077b4524"
      },
      "source": [
        "pip install nltk spacy"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0143447e",
        "outputId": "baf6f308-439e-4550-b23a-019043dc5b83"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdd5bc9b",
        "outputId": "2de0cadf-9ef0-4255-c13e-79b878506e53"
      },
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78ca33d9"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8a4ed84"
      },
      "source": [
        "medical_text = \"A recent study investigated the efficacy of a new drug, \\\"NeuroHeal,\\\" in treating patients with Alzheimer's disease. Participants exhibited cognitive decline and amyloid plaque accumulation. The treatment group showed significant improvements in memory recall and daily functioning compared to the placebo group. Further research is needed to understand long-term effects and potential side effects such as nausea or dizziness.\"\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "464a5751"
      },
      "source": [
        "## Tokenize Text\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d99cb49a",
        "outputId": "15179eae-7fe9-4d2c-b272-2314346cf747"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "nltk_sentences = sent_tokenize(medical_text)\n",
        "print(\"NLTK Sentence Tokenization (first 3 sentences):\")\n",
        "for i, sent in enumerate(nltk_sentences[:3]):\n",
        "    print(f\"  {i+1}. {sent}\")\n",
        "\n",
        "if nltk_sentences:\n",
        "    first_sentence_nltk = nltk_sentences[0]\n",
        "    nltk_words = word_tokenize(first_sentence_nltk)\n",
        "    print(\"\\nNLTK Word Tokenization (first 10 words of the first sentence):\")\n",
        "    print(nltk_words[:10])\n",
        "else:\n",
        "    print(\"\\nNo sentences found for NLTK word tokenization.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Sentence Tokenization (first 3 sentences):\n",
            "  1. A recent study investigated the efficacy of a new drug, \"NeuroHeal,\" in treating patients with Alzheimer's disease.\n",
            "  2. Participants exhibited cognitive decline and amyloid plaque accumulation.\n",
            "  3. The treatment group showed significant improvements in memory recall and daily functioning compared to the placebo group.\n",
            "\n",
            "NLTK Word Tokenization (first 10 words of the first sentence):\n",
            "['A', 'recent', 'study', 'investigated', 'the', 'efficacy', 'of', 'a', 'new', 'drug']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3699da87",
        "outputId": "5d472c10-8e8d-4880-f727-caae3345df8b"
      },
      "source": [
        "spacy_doc = nlp(medical_text)\n",
        "\n",
        "spacy_sentences = [sent.text for sent in spacy_doc.sents]\n",
        "print(\"\\nspaCy Sentence Tokenization (first 3 sentences):\")\n",
        "for i, sent in enumerate(spacy_sentences[:3]):\n",
        "    print(f\"  {i+1}. {sent}\")\n",
        "\n",
        "if spacy_sentences:\n",
        "    first_sentence_spacy = nlp(spacy_sentences[0]) # Re-process the sentence to get token objects\n",
        "    spacy_words = [token.text for token in first_sentence_spacy]\n",
        "    print(\"\\nspaCy Word Tokenization (first 10 words of the first sentence):\")\n",
        "    print(spacy_words[:10])\n",
        "else:\n",
        "    print(\"\\nNo sentences found for spaCy word tokenization.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "spaCy Sentence Tokenization (first 3 sentences):\n",
            "  1. A recent study investigated the efficacy of a new drug, \"NeuroHeal,\" in treating patients with Alzheimer's disease.\n",
            "  2. Participants exhibited cognitive decline and amyloid plaque accumulation.\n",
            "  3. The treatment group showed significant improvements in memory recall and daily functioning compared to the placebo group.\n",
            "\n",
            "spaCy Word Tokenization (first 10 words of the first sentence):\n",
            "['A', 'recent', 'study', 'investigated', 'the', 'efficacy', 'of', 'a', 'new', 'drug']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6827b332"
      },
      "source": [
        "## Apply Stemming\n",
        "\n",
        "### Subtask:\n",
        "Using NLTK's PorterStemmer or SnowballStemmer, apply stemming to the tokenized words from the medical text, focusing on medical terminology. Display the original words and their stemmed versions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0018b17a",
        "outputId": "61b322dd-06fd-4bcf-90f3-47125acc6fe7"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "# Select a sample of words for stemming\n",
        "# Using nltk_words which was generated previously\n",
        "sample_words = [\n",
        "    \"investigated\", \"efficacy\", \"treating\", \"patients\", \"disease\",\n",
        "    \"exhibited\", \"cognitive\", \"accumulation\", \"improved\", \"functioning\",\n",
        "    \"research\", \"effects\", \"side\", \"nausea\", \"dizziness\"\n",
        "]\n",
        "\n",
        "print(\"NLTK Porter Stemmer Results:\")\n",
        "print(\"-----------------------------\")\n",
        "for word in sample_words:\n",
        "    stemmed_word = porter_stemmer.stem(word)\n",
        "    print(f\"Original: {word:<15} Stemmed: {stemmed_word}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Porter Stemmer Results:\n",
            "-----------------------------\n",
            "Original: investigated    Stemmed: investig\n",
            "Original: efficacy        Stemmed: efficaci\n",
            "Original: treating        Stemmed: treat\n",
            "Original: patients        Stemmed: patient\n",
            "Original: disease         Stemmed: diseas\n",
            "Original: exhibited       Stemmed: exhibit\n",
            "Original: cognitive       Stemmed: cognit\n",
            "Original: accumulation    Stemmed: accumul\n",
            "Original: improved        Stemmed: improv\n",
            "Original: functioning     Stemmed: function\n",
            "Original: research        Stemmed: research\n",
            "Original: effects         Stemmed: effect\n",
            "Original: side            Stemmed: side\n",
            "Original: nausea          Stemmed: nausea\n",
            "Original: dizziness       Stemmed: dizzi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39b93f46"
      },
      "source": [
        "## Apply Lemmatization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c93fed6",
        "outputId": "cdaea2b5-0d37-4058-b219-35b61e283699"
      },
      "source": [
        "print(\"spaCy Lemmatization Results:\")\n",
        "print(\"----------------------------\")\n",
        "\n",
        "# Reuse the sample_words from the stemming subtask for consistency\n",
        "# Convert to set for efficient lookup\n",
        "sample_words_set = set(sample_words)\n",
        "\n",
        "# spacy_doc was created earlier by nlp(medical_text)\n",
        "\n",
        "lemmatized_results = {}\n",
        "for token in spacy_doc:\n",
        "    # Only consider tokens that are words and are in our sample_words list\n",
        "    # Convert token.text to lowercase for a more robust comparison with sample_words\n",
        "    if token.text.lower() in sample_words_set or token.text in sample_words_set:\n",
        "        lemmatized_results[token.text] = token.lemma_\n",
        "\n",
        "# Print results for words that were found in the document and match our sample list\n",
        "for word in sample_words:\n",
        "    if word in lemmatized_results:\n",
        "        print(f\"Original: {word:<15} Lemmatized: {lemmatized_results[word]}\")\n",
        "    # Handle cases where the word might not be directly in spacy_doc's tokens (e.g., due to punctuation, capitalization)\n",
        "    elif word.lower() in [t.text.lower() for t in spacy_doc]:\n",
        "        # Find the lemma for the lowercased version if present\n",
        "        for token in spacy_doc:\n",
        "            if token.text.lower() == word.lower():\n",
        "                print(f\"Original: {word:<15} Lemmatized: {token.lemma_}\")\n",
        "                break\n",
        "    else:\n",
        "        # For words in sample_words that were not directly found as tokens in spacy_doc\n",
        "        # This might happen if 'NeuroHeal' is in sample_words but spacy tokenizes it differently\n",
        "        pass # We only care about words present in the doc tokens.\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy Lemmatization Results:\n",
            "----------------------------\n",
            "Original: investigated    Lemmatized: investigate\n",
            "Original: efficacy        Lemmatized: efficacy\n",
            "Original: treating        Lemmatized: treat\n",
            "Original: patients        Lemmatized: patient\n",
            "Original: disease         Lemmatized: disease\n",
            "Original: exhibited       Lemmatized: exhibit\n",
            "Original: cognitive       Lemmatized: cognitive\n",
            "Original: accumulation    Lemmatized: accumulation\n",
            "Original: functioning     Lemmatized: function\n",
            "Original: research        Lemmatized: research\n",
            "Original: effects         Lemmatized: effect\n",
            "Original: side            Lemmatized: side\n",
            "Original: nausea          Lemmatized: nausea\n",
            "Original: dizziness       Lemmatized: dizziness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33b06295",
        "outputId": "fa5ae2f9-98fd-4c29-ff7d-731fec554ce0"
      },
      "source": [
        "stemmed_words_comparison = []\n",
        "lemmatized_words_comparison = []\n",
        "\n",
        "for word in sample_words:\n",
        "    stemmed_words_comparison.append(porter_stemmer.stem(word))\n",
        "    # Retrieve lemma from the previously generated lemmatized_results\n",
        "    # Need to handle cases where a word might not be directly in lemmatized_results key (e.g., due to case)\n",
        "    lemma = None\n",
        "    if word in lemmatized_results:\n",
        "        lemma = lemmatized_results[word]\n",
        "    elif word.lower() in [t.text.lower() for t in spacy_doc]:\n",
        "        for token in spacy_doc:\n",
        "            if token.text.lower() == word.lower():\n",
        "                lemma = token.lemma_\n",
        "                break\n",
        "    lemmatized_words_comparison.append(lemma if lemma else word) # Default to original word if lemma not found\n",
        "\n",
        "comparison = list(zip(stemmed_words_comparison, lemmatized_words_comparison))\n",
        "\n",
        "print(\"Stemming vs Lemmatization (Sample Words):\")\n",
        "print(\"----------------------------------------\")\n",
        "print(f\"{\"Original\":<15} {\"Stemmed\":<15} {\"Lemmatized\":<15}\")\n",
        "print(f\"{\"-\"*15} {\"-\"*15} {\"-\"*15}\")\n",
        "for i, (stemmed, lemmatized) in enumerate(comparison):\n",
        "    print(f\"{sample_words[i]:<15} {stemmed:<15} {lemmatized:<15}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming vs Lemmatization (Sample Words):\n",
            "----------------------------------------\n",
            "Original        Stemmed         Lemmatized     \n",
            "--------------- --------------- ---------------\n",
            "investigated    investig        investigate    \n",
            "efficacy        efficaci        efficacy       \n",
            "treating        treat           treat          \n",
            "patients        patient         patient        \n",
            "disease         diseas          disease        \n",
            "exhibited       exhibit         exhibit        \n",
            "cognitive       cognit          cognitive      \n",
            "accumulation    accumul         accumulation   \n",
            "improved        improv          improved       \n",
            "functioning     function        function       \n",
            "research        research        research       \n",
            "effects         effect          effect         \n",
            "side            side            side           \n",
            "nausea          nausea          nausea         \n",
            "dizziness       dizzi           dizziness      \n"
          ]
        }
      ]
    }
  ]
}