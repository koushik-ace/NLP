{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik-ace/NLP/blob/main/Assignment_6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA with sample data\n"
      ],
      "metadata": {
        "id": "4rRHP_23L770"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"/content/LDA-Data.xlsx\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "p5U4R_m7IyMo",
        "outputId": "fd6bb355-e660-43b0-f9f5-3fba226cf0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             News\n",
              "0   Virat scored century in match\n",
              "1            BJP won in elections\n",
              "2  Bumra took 5 wicket in a match\n",
              "3  Congress form state government"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-948c1dfb-7eb0-415b-921e-7bbbd7cb7277\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Virat scored century in match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BJP won in elections</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bumra took 5 wicket in a match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Congress form state government</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-948c1dfb-7eb0-415b-921e-7bbbd7cb7277')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-948c1dfb-7eb0-415b-921e-7bbbd7cb7277 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-948c1dfb-7eb0-415b-921e-7bbbd7cb7277');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"News\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"BJP won in elections\",\n          \"Congress form state government\",\n          \"Virat scored century in match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data (including punkt_tab)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)  # Changed from 'punkt' to 'punkt_tab'\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Handle non-string inputs\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # 1. Clean Text: convert to lowercase, remove non-alphabetic characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "\n",
        "    # 2. Word Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # 3. Stopword removal & 4. Lemmatization\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:  # Remove single character words\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "    # 5. Rejoin\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "df['News'] = df['News'].fillna('')\n",
        "\n",
        "# Apply the preprocessing function to the 'News' column\n",
        "df['Processed_News'] = df['News'].apply(preprocess_text)\n",
        "\n",
        "print(\"Original News and Processed News:\")\n",
        "print(df[['News', 'Processed_News']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbn6u3tQKIJN",
        "outputId": "493149b9-e951-45fe-cea4-c451708da4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original News and Processed News:\n",
            "                             News                  Processed_News\n",
            "0   Virat scored century in match      virat scored century match\n",
            "1            BJP won in elections                    bjp election\n",
            "2  Bumra took 5 wicket in a match         bumra took wicket match\n",
            "3  Congress form state government  congress form state government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the 'Processed_News' column to create the BoW matrix\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_News'])\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Vocabulary (Feature Names):\")\n",
        "print(feature_names)\n",
        "print(\"\\nShape of BoW matrix:\", bow_matrix.shape)\n",
        "\n",
        "# To display a part of the BoW matrix, convert it to a DataFrame (optional, for better viewing)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=feature_names)\n",
        "print(\"\\nFirst 5 rows of the BoW matrix:\")\n",
        "print(bow_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtU_4oXIKPDi",
        "outputId": "21b871b6-15c9-45a6-e04c-13ed48051c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (Feature Names):\n",
            "['bjp' 'bumra' 'century' 'congress' 'election' 'form' 'government' 'match'\n",
            " 'scored' 'state' 'took' 'virat' 'wicket']\n",
            "\n",
            "Shape of BoW matrix: (4, 13)\n",
            "\n",
            "First 5 rows of the BoW matrix:\n",
            "   bjp  bumra  century  congress  election  form  government  match  scored  \\\n",
            "0    0      0        1         0         0     0           0      1       1   \n",
            "1    1      0        0         0         1     0           0      0       0   \n",
            "2    0      1        0         0         0     0           0      1       0   \n",
            "3    0      0        0         1         0     1           1      0       0   \n",
            "\n",
            "   state  took  virat  wicket  \n",
            "0      0     0      1       0  \n",
            "1      0     0      0       0  \n",
            "2      0     1      0       1  \n",
            "3      1     0      0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuAcPo4aKeBy",
        "outputId": "4d5df628-08bb-49fd-c4ce-829e3dfc1048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   bjp  bumra  century  congress  election  form  government  match  scored  \\\n",
            "0    0      0        1         0         0     0           0      1       1   \n",
            "1    1      0        0         0         1     0           0      0       0   \n",
            "2    0      1        0         0         0     0           0      1       0   \n",
            "3    0      0        0         1         0     1           1      0       0   \n",
            "\n",
            "   state  took  virat  wicket  \n",
            "0      0     0      1       0  \n",
            "1      0     0      0       0  \n",
            "2      0     1      0       1  \n",
            "3      1     0      0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Define the number of topics (you can change this based on your needs)\n",
        "num_topics = 2\n",
        "\n",
        "# Initialize LDA model\n",
        "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "\n",
        "# Fit the model to the BoW matrix\n",
        "lda_output = lda_model.fit_transform(bow_matrix)\n",
        "\n",
        "# Display the topics and their top words\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_): # Corrected from components__ to components_\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "no_top_words = 5\n",
        "print(\"\\nLDA Topics:\")\n",
        "display_topics(lda_model, feature_names, no_top_words)\n",
        "\n",
        "# Add the dominant topic to the original DataFrame\n",
        "df['Dominant_Topic'] = lda_output.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with Dominant Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Ag-VFTKtdl",
        "outputId": "8c752d5c-dcfb-47c4-d80d-1d298e3b1c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LDA Topics:\n",
            "Topic 0:\n",
            "form government congress state election\n",
            "Topic 1:\n",
            "match virat century scored took\n",
            "\n",
            "DataFrame with Dominant Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               1\n",
            "1            BJP won in elections               0\n",
            "2  Bumra took 5 wicket in a match               1\n",
            "3  Congress form state government               0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the topics and their top words again in this cell\n",
        "# Reusing the 'display_topics' function, 'lda_model', 'feature_names', and 'no_top_words' from previous execution\n",
        "print(\"LDA Topics:\")\n",
        "display_topics(lda_model, feature_names, no_top_words)\n",
        "\n",
        "print(\"\\nDataFrame with News and their Dominant Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFs-gE1GLTze",
        "outputId": "8dc5d2bb-9ad8-4316-976e-836dbe92070e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Topics:\n",
            "Topic 0:\n",
            "form government congress state election\n",
            "Topic 1:\n",
            "match virat century scored took\n",
            "\n",
            "DataFrame with News and their Dominant Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               1\n",
            "1            BJP won in elections               0\n",
            "2  Bumra took 5 wicket in a match               1\n",
            "3  Congress form state government               0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA with kaggle data"
      ],
      "metadata": {
        "id": "J1f1JG4qMCXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\", on_bad_lines='skip', engine='python', nrows=1000)\n",
        "\n",
        "# PREPROCESS\n",
        "df['titles'] = df['titles'].fillna('')\n",
        "df['summaries'] = df['summaries'].fillna('')\n",
        "df['text_content'] = df['titles'] + ' ' + df['summaries']\n",
        "df['Processed_Text'] = df['text_content'].apply(preprocess_text)\n",
        "\n",
        "# BOW\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_Text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "lda_output = lda_model.fit_transform(bow_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"LDA Topics:\")\n",
        "display_topics(lda_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = lda_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['text_content', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "LvCUEtZ_XE4E",
        "outputId": "b09cc693-f1e5-44e8-f4cf-867fb16ca60e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Topics:\n",
            "Topic 0:\n",
            "segmentation image network method model\n",
            "Topic 1:\n",
            "image segmentation domain method learning\n",
            "\n",
            "Document and Topic:\n",
            "                                          text_content  Dominant_Topic\n",
            "0    Survey on Semantic Stereo Matching / Semantic ...               0\n",
            "1    FUTURE-AI: Guiding Principles and Consensus Re...               1\n",
            "2    Enforcing Mutual Consistency of Hard Regions f...               0\n",
            "3    Parameter Decoupling Strategy for Semi-supervi...               0\n",
            "4    Background-Foreground Segmentation for Interio...               0\n",
            "..                                                 ...             ...\n",
            "995  DeepIGeoS: A Deep Interactive Geodesic Framewo...               0\n",
            "996  3D Densely Convolutional Networks for Volumetr...               0\n",
            "997  UI-Net: Interactive Artificial Neural Networks...               0\n",
            "998  One-Shot Learning for Semantic Segmentation Lo...               0\n",
            "999  Exploring and Exploiting Diversity for Image S...               0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with kaggle data"
      ],
      "metadata": {
        "id": "aeXJgUQCUQIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\", on_bad_lines='skip', engine='python', nrows=1000)\n",
        "\n",
        "# PREPROCESS\n",
        "df['titles'] = df['titles'].fillna('')\n",
        "df['summaries'] = df['summaries'].fillna('')\n",
        "df['text_content'] = df['titles'] + ' ' + df['summaries']\n",
        "df['Processed_Text'] = df['text_content'].apply(preprocess_text)\n",
        "\n",
        "# BOW\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_Text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_output = nmf_model.fit_transform(bow_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"NMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['text_content', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "3V0H4lgEXXVz",
        "outputId": "f2a0beae-b367-45eb-8605-08736eb92543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic 0:\n",
            "segmentation network learning model method\n",
            "Topic 1:\n",
            "image segmentation method based using\n",
            "\n",
            "Document and Topic:\n",
            "                                          text_content  Dominant_Topic\n",
            "0    Survey on Semantic Stereo Matching / Semantic ...               0\n",
            "1    FUTURE-AI: Guiding Principles and Consensus Re...               1\n",
            "2    Enforcing Mutual Consistency of Hard Regions f...               0\n",
            "3    Parameter Decoupling Strategy for Semi-supervi...               0\n",
            "4    Background-Foreground Segmentation for Interio...               0\n",
            "..                                                 ...             ...\n",
            "995  DeepIGeoS: A Deep Interactive Geodesic Framewo...               0\n",
            "996  3D Densely Convolutional Networks for Volumetr...               0\n",
            "997  UI-Net: Interactive Artificial Neural Networks...               0\n",
            "998  One-Shot Learning for Semantic Segmentation Lo...               1\n",
            "999  Exploring and Exploiting Diversity for Image S...               0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with sample data\n"
      ],
      "metadata": {
        "id": "YJM2bmWnSSaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"/content/LDA-Data.xlsx\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "ce086849-9a49-41a2-848b-df260ff46f87",
        "id": "ZC0Qk5o1Sa6r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             News\n",
              "0   Virat scored century in match\n",
              "1            BJP won in elections\n",
              "2  Bumra took 5 wicket in a match\n",
              "3  Congress form state government"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c65876d-750e-4744-b0e7-c7db400075ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Virat scored century in match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BJP won in elections</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bumra took 5 wicket in a match</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Congress form state government</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c65876d-750e-4744-b0e7-c7db400075ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c65876d-750e-4744-b0e7-c7db400075ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c65876d-750e-4744-b0e7-c7db400075ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"News\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"BJP won in elections\",\n          \"Congress form state government\",\n          \"Virat scored century in match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK data (including punkt_tab)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)  # Changed from 'punkt' to 'punkt_tab'\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "# Initialize lemmatizer and stopwords\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Handle non-string inputs\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # 1. Clean Text: convert to lowercase, remove non-alphabetic characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "\n",
        "    # 2. Word Tokenization\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # 3. Stopword removal & 4. Lemmatization\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:  # Remove single character words\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "    # 5. Rejoin\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "df['News'] = df['News'].fillna('')\n",
        "\n",
        "# Apply the preprocessing function to the 'News' column\n",
        "df['Processed_News'] = df['News'].apply(preprocess_text)\n",
        "\n",
        "print(\"Original News and Processed News:\")\n",
        "print(df[['News', 'Processed_News']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3921dcd-9ced-4cd7-ec3f-ac3db4db2c1c",
        "id": "uYvUg1gjSj5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original News and Processed News:\n",
            "                             News                  Processed_News\n",
            "0   Virat scored century in match      virat scored century match\n",
            "1            BJP won in elections                    bjp election\n",
            "2  Bumra took 5 wicket in a match         bumra took wicket match\n",
            "3  Congress form state government  congress form state government\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the 'Processed_News' column to create the BoW matrix\n",
        "bow_matrix = vectorizer.fit_transform(df['Processed_News'])\n",
        "\n",
        "# Get the feature names (vocabulary)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "print(\"Vocabulary (Feature Names):\")\n",
        "print(feature_names)\n",
        "print(\"\\nShape of BoW matrix:\", bow_matrix.shape)\n",
        "\n",
        "# To display a part of the BoW matrix, convert it to a DataFrame (optional, for better viewing)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=feature_names)\n",
        "print(\"\\nFirst 5 rows of the BoW matrix:\")\n",
        "print(bow_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474ebd10-230c-49e0-e346-f627469014b1",
        "id": "-ZhP5C9tS-HE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary (Feature Names):\n",
            "['bjp' 'bumra' 'century' 'congress' 'election' 'form' 'government' 'match'\n",
            " 'scored' 'state' 'took' 'virat' 'wicket']\n",
            "\n",
            "Shape of BoW matrix: (4, 13)\n",
            "\n",
            "First 5 rows of the BoW matrix:\n",
            "   bjp  bumra  century  congress  election  form  government  match  scored  \\\n",
            "0    0      0        1         0         0     0           0      1       1   \n",
            "1    1      0        0         0         1     0           0      0       0   \n",
            "2    0      1        0         0         0     0           0      1       0   \n",
            "3    0      0        0         1         0     1           1      0       0   \n",
            "\n",
            "   state  took  virat  wicket  \n",
            "0      0     0      1       0  \n",
            "1      0     0      0       0  \n",
            "2      0     1      0       1  \n",
            "3      1     0      0       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Define the number of topics (you can change this based on your needs)\n",
        "num_topics = 2\n",
        "\n",
        "# Initialize NMF model\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42, init='nndsvda', tol=5e-3)\n",
        "\n",
        "# Fit the model to the BoW matrix\n",
        "nmf_output = nmf_model.fit_transform(bow_matrix)\n",
        "\n",
        "# Display the topics and their top words\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "no_top_words = 5\n",
        "print(\"\\nNMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, no_top_words)\n",
        "\n",
        "# Add the dominant topic to the original DataFrame\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "\n",
        "print(\"\\nDataFrame with Dominant Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59b50a9-64e4-4287-af4f-398f75a4ac58",
        "id": "LLiKBpVfTDfQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NMF Topics:\n",
            "Topic 0:\n",
            "match scored virat century wicket\n",
            "Topic 1:\n",
            "state form congress government election\n",
            "\n",
            "DataFrame with Dominant Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               0\n",
            "1            BJP won in elections               1\n",
            "2  Bumra took 5 wicket in a match               0\n",
            "3  Congress form state government               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with sample data tf idf\n"
      ],
      "metadata": {
        "id": "6DikPLK4YTE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "data = {'News': ['Virat scored century in match', 'BJP won in elections', 'Bumra took 5 wicket in a match', 'Congress form state government']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# PREPROCESS\n",
        "df['News'] = df['News'].fillna('')\n",
        "df['Processed_News'] = df['News'].apply(preprocess_text)\n",
        "\n",
        "# TFIDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Processed_News'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"NMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['News', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "N4kSnoJXYRVj",
        "outputId": "818cd83e-7365-495a-feda-73e85e5dee0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic 0:\n",
            "match bumra wicket took virat\n",
            "Topic 1:\n",
            "election bjp form government state\n",
            "\n",
            "Document and Topic:\n",
            "                             News  Dominant_Topic\n",
            "0   Virat scored century in match               0\n",
            "1            BJP won in elections               1\n",
            "2  Bumra took 5 wicket in a match               0\n",
            "3  Congress form state government               1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NMF with kaggle data TF IDF"
      ],
      "metadata": {
        "id": "NMGaMCNaX9Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    words = nltk.word_tokenize(text)\n",
        "    processed_words = []\n",
        "    for word in words:\n",
        "        if word not in stop_words and len(word) > 1:\n",
        "            processed_words.append(lemmatizer.lemmatize(word))\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# LOAD\n",
        "df = pd.read_csv(\"/content/arxiv_data.csv\", on_bad_lines='skip', engine='python', nrows=1000)\n",
        "\n",
        "# PREPROCESS\n",
        "df['titles'] = df['titles'].fillna('')\n",
        "df['summaries'] = df['summaries'].fillna('')\n",
        "df['text_content'] = df['titles'] + ' ' + df['summaries']\n",
        "df['Processed_Text'] = df['text_content'].apply(preprocess_text)\n",
        "\n",
        "# TFIDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['Processed_Text'])\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# OUTPUT\n",
        "num_topics = 2\n",
        "nmf_model = NMF(n_components=num_topics, random_state=42)\n",
        "nmf_output = nmf_model.fit_transform(tfidf_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "print(\"NMF Topics:\")\n",
        "display_topics(nmf_model, feature_names, 5)\n",
        "df['Dominant_Topic'] = nmf_output.argmax(axis=1)\n",
        "print(\"\\nDocument and Topic:\")\n",
        "print(df[['text_content', 'Dominant_Topic']])"
      ],
      "metadata": {
        "id": "iYfPt6e-XgbL",
        "outputId": "368a6ba2-53ad-4e1a-bc5a-68f4f9c1dd72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic 0:\n",
            "segmentation image network method model\n",
            "Topic 1:\n",
            "domain supervised data learning annotation\n",
            "\n",
            "Document and Topic:\n",
            "                                          text_content  Dominant_Topic\n",
            "0    Survey on Semantic Stereo Matching / Semantic ...               0\n",
            "1    FUTURE-AI: Guiding Principles and Consensus Re...               0\n",
            "2    Enforcing Mutual Consistency of Hard Regions f...               1\n",
            "3    Parameter Decoupling Strategy for Semi-supervi...               1\n",
            "4    Background-Foreground Segmentation for Interio...               0\n",
            "..                                                 ...             ...\n",
            "995  DeepIGeoS: A Deep Interactive Geodesic Framewo...               0\n",
            "996  3D Densely Convolutional Networks for Volumetr...               0\n",
            "997  UI-Net: Interactive Artificial Neural Networks...               0\n",
            "998  One-Shot Learning for Semantic Segmentation Lo...               0\n",
            "999  Exploring and Exploiting Diversity for Image S...               0\n",
            "\n",
            "[1000 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVAyCQqJKq2bdwtM9/564Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}