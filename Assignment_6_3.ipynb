{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik-ace/NLP/blob/main/Assignment_6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXqW2rFCEXrI",
        "outputId": "b01197c8-0630-4c08-d1bd-189ace3d48b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/spsayakpaul/arxiv-paper-abstracts/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"spsayakpaul/arxiv-paper-abstracts\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PL5H-aanEx8m",
        "outputId": "bf0c65bb-19e4-4603-831a-8abee153db71"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 51774,\n  \"fields\": [\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38972,\n        \"samples\": [\n          \"Sum-Product-Transform Networks: Exploiting Symmetries using Invertible Transformations\",\n          \"A Primal-Dual Subgradient Approachfor Fair Meta Learning\",\n          \"Adversarial Multi-Source Transfer Learning in Healthcare: Application to Glucose Prediction for Diabetic People\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 38979,\n        \"samples\": [\n          \"Continual learning (CL) is a setting in which an agent has to learn from an\\nincoming stream of data during its entire lifetime. Although major advances\\nhave been made in the field, one recurring problem which remains unsolved is\\nthat of Catastrophic Forgetting (CF). While the issue has been extensively\\nstudied empirically, little attention has been paid from a theoretical angle.\\nIn this paper, we show that the impact of CF increases as two tasks\\nincreasingly align. We introduce a measure of task similarity called the NTK\\noverlap matrix which is at the core of CF. We analyze common projected gradient\\nalgorithms and demonstrate how they mitigate forgetting. Then, we propose a\\nvariant of Orthogonal Gradient Descent (OGD) which leverages structure of the\\ndata through Principal Component Analysis (PCA). Experiments support our\\ntheoretical findings and show how our method can help reduce CF on classical CL\\ndatasets.\",\n          \"Few-shot learning is a challenging task since only few instances are given\\nfor recognizing an unseen class. One way to alleviate this problem is to\\nacquire a strong inductive bias via meta-learning on similar tasks. In this\\npaper, we show that such inductive bias can be learned from a flat collection\\nof unlabeled images, and instantiated as transferable representations among\\nseen and unseen classes. Specifically, we propose a novel part-based\\nself-supervised representation learning scheme to learn transferable\\nrepresentations by maximizing the similarity of an image to its discriminative\\npart. To mitigate the overfitting in few-shot classification caused by data\\nscarcity, we further propose a part augmentation strategy by retrieving extra\\nimages from a base dataset. We conduct systematic studies on miniImageNet and\\ntieredImageNet benchmarks. Remarkably, our method yields impressive results,\\noutperforming the previous best unsupervised methods by 7.74% and 9.24% under\\n5-way 1-shot and 5-way 5-shot settings, which are comparable with\\nstate-of-the-art supervised methods.\",\n          \"Surgical instrument segmentation is extremely important for computer-assisted\\nsurgery. Different from common object segmentation, it is more challenging due\\nto the large illumination and scale variation caused by the special surgical\\nscenes. In this paper, we propose a novel bilinear attention network with\\nadaptive receptive field to solve these two challenges. For the illumination\\nvariation, the bilinear attention module can capture second-order statistics to\\nencode global contexts and semantic dependencies between local pixels. With\\nthem, semantic features in challenging areas can be inferred from their\\nneighbors and the distinction of various semantics can be boosted. For the\\nscale variation, our adaptive receptive field module aggregates multi-scale\\nfeatures and automatically fuses them with different weights. Specifically, it\\nencodes the semantic relationship between channels to emphasize feature maps\\nwith appropriate scales, changing the receptive field of subsequent\\nconvolutions. The proposed network achieves the best performance 97.47% mean\\nIOU on Cata7 and comes first place on EndoVis 2017 by 10.10% IOU overtaking\\nsecond-ranking method.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"terms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3157,\n        \"samples\": [\n          \"['cs.LG', 'cs.CE', 'q-fin.ST', 'stat.ML']\",\n          \"['cs.LG', 'physics.comp-ph', 'physics.flu-dyn']\",\n          \"['cs.LG', 'cs.CV', 'math.AT']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7e6b0eae-334a-4918-9a1d-adf53b87dbe4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e6b0eae-334a-4918-9a1d-adf53b87dbe4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e6b0eae-334a-4918-9a1d-adf53b87dbe4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e6b0eae-334a-4918-9a1d-adf53b87dbe4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(f'{path}/arxiv_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5416df"
      },
      "source": [
        "## Prepare Corpus\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79472e44",
        "outputId": "1d8f5626-ebf3-43ca-a5dd-1417836d0df6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    Stereo matching is one of the widely used tech...\n",
            "1    The recent advancements in artificial intellig...\n",
            "2    In this paper, we proposed a novel mutual cons...\n",
            "3    Consistency training has proven to be an advan...\n",
            "4    To ensure safety in automated driving, the cor...\n",
            "Name: summaries, dtype: object\n"
          ]
        }
      ],
      "source": [
        "corpus = df['summaries']\n",
        "print(corpus.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "557f7d51",
        "outputId": "d7c970a2-684c-4811-f17b-474f4de583f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    stereo matching is one of the widely used tech...\n",
            "1    the recent advancements in artificial intellig...\n",
            "2    in this paper we proposed a novel mutual consi...\n",
            "3    consistency training has proven to be an advan...\n",
            "4    to ensure safety in automated driving the corr...\n",
            "Name: summaries, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text) # Remove numbers\n",
        "    text = re.sub(r'[\\W_]+', ' ', text) # Remove punctuation and special characters, replace with space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces and strip leading/trailing spaces\n",
        "    return text\n",
        "\n",
        "cleaned_corpus = corpus.apply(clean_text)\n",
        "print(cleaned_corpus.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1114a24a",
        "outputId": "2b27d693-6f89-413b-a413-34c15c0d6c66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    [stereo, matching, one, widely, used, techniqu...\n",
            "1    [recent, advancements, artificial, intelligenc...\n",
            "2    [paper, proposed, novel, mutual, consistency, ...\n",
            "3    [consistency, training, proven, advanced, semi...\n",
            "4    [ensure, safety, automated, driving, correct, ...\n",
            "Name: summaries, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab') # Added to resolve LookupError\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_and_remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "tokenized_corpus = cleaned_corpus.apply(tokenize_and_remove_stopwords)\n",
        "print(tokenized_corpus.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "28abc96b",
        "outputId": "5a7f70a5-2643-48e1-bdea-02b1743ad789"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    [stereo, matching, one, widely, used, techniqu...\n",
            "1    [recent, advancement, artificial, intelligence...\n",
            "2    [paper, proposed, novel, mutual, consistency, ...\n",
            "3    [consistency, training, proven, advanced, semi...\n",
            "4    [ensure, safety, automated, driving, correct, ...\n",
            "Name: summaries, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4') # Required for WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return lemmas\n",
        "\n",
        "lemmatized_corpus = tokenized_corpus.apply(lemmatize_tokens)\n",
        "print(lemmatized_corpus.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5bb4984e",
        "outputId": "6deb247a-ff43-408a-ea5d-89173210b84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eb2aa455",
        "outputId": "90e31778-2aea-4416-dcfa-6c03a2e6983c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique tokens in dictionary: 15487\n",
            "First 5 entries of the BoW corpus:\n",
            "Document 0: [(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 2), (29, 2), (30, 4), (31, 1), (32, 1), (33, 1), (34, 1), (35, 2), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 2), (49, 2), (50, 1), (51, 1), (52, 2), (53, 1), (54, 5), (55, 1), (56, 2), (57, 1), (58, 1), (59, 1), (60, 2), (61, 1)]\n",
            "Document 1: [(4, 1), (16, 2), (23, 3), (29, 1), (37, 1), (41, 1), (42, 1), (47, 1), (48, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 8), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 3), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 3), (106, 1), (107, 1), (108, 2), (109, 3), (110, 1), (111, 1), (112, 1), (113, 6), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 4), (123, 1), (124, 1), (125, 1), (126, 1), (127, 1), (128, 2), (129, 3), (130, 2), (131, 1), (132, 1), (133, 2), (134, 1), (135, 1), (136, 3), (137, 1), (138, 1), (139, 2), (140, 1), (141, 1), (142, 1), (143, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 2), (149, 1), (150, 1), (151, 1), (152, 1), (153, 1), (154, 1), (155, 1), (156, 1)]\n",
            "Document 2: [(6, 1), (7, 2), (14, 1), (23, 3), (35, 2), (37, 1), (39, 2), (45, 2), (48, 5), (53, 2), (68, 1), (89, 1), (103, 1), (122, 3), (157, 1), (158, 1), (159, 1), (160, 2), (161, 1), (162, 1), (163, 1), (164, 1), (165, 2), (166, 1), (167, 1), (168, 1), (169, 1), (170, 4), (171, 1), (172, 1), (173, 1), (174, 2), (175, 1), (176, 2), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 1), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 2), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 4), (206, 1), (207, 1), (208, 1), (209, 2), (210, 2), (211, 4), (212, 3), (213, 1), (214, 1), (215, 1), (216, 3), (217, 1), (218, 1), (219, 1), (220, 1), (221, 1), (222, 1), (223, 4), (224, 1), (225, 1), (226, 1), (227, 1), (228, 5), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 5), (237, 1), (238, 1), (239, 1), (240, 1), (241, 1), (242, 2), (243, 2), (244, 1), (245, 2), (246, 3), (247, 1), (248, 1)]\n",
            "Document 3: [(7, 1), (10, 1), (23, 2), (25, 1), (45, 2), (48, 3), (53, 2), (70, 2), (89, 1), (104, 2), (107, 1), (122, 1), (159, 2), (165, 3), (174, 2), (186, 1), (188, 3), (189, 1), (213, 1), (217, 1), (218, 4), (219, 1), (228, 3), (234, 1), (236, 3), (237, 1), (242, 3), (243, 2), (246, 1), (249, 1), (250, 2), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 2), (258, 1), (259, 1), (260, 1), (261, 1), (262, 1), (263, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 2), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 2), (275, 1), (276, 1), (277, 2), (278, 1), (279, 1), (280, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 2), (291, 1), (292, 4), (293, 1), (294, 2), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 3), (308, 1)]\n",
            "Document 4: [(4, 1), (14, 2), (17, 2), (18, 1), (23, 2), (32, 1), (41, 1), (48, 2), (50, 1), (55, 1), (67, 1), (68, 1), (70, 2), (89, 2), (134, 1), (171, 1), (174, 4), (176, 3), (191, 2), (200, 1), (217, 1), (233, 1), (240, 1), (242, 1), (243, 1), (247, 1), (256, 1), (295, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 1), (314, 2), (315, 1), (316, 3), (317, 1), (318, 2), (319, 2), (320, 1), (321, 1), (322, 1), (323, 3), (324, 1), (325, 1), (326, 1), (327, 1), (328, 1), (329, 1), (330, 1), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 1), (343, 3), (344, 1), (345, 2), (346, 1), (347, 1), (348, 2), (349, 1), (350, 1), (351, 2), (352, 1), (353, 2), (354, 4), (355, 1), (356, 1), (357, 2), (358, 4), (359, 1), (360, 1), (361, 2), (362, 1), (363, 1), (364, 2), (365, 1), (366, 1), (367, 1), (368, 1), (369, 1), (370, 1), (371, 1), (372, 2), (373, 1), (374, 1), (375, 1), (376, 1), (377, 1), (378, 1), (379, 3), (380, 1), (381, 1), (382, 1), (383, 1), (384, 2), (385, 4), (386, 1), (387, 1), (388, 1), (389, 2), (390, 1), (391, 1), (392, 1), (393, 1), (394, 1), (395, 1), (396, 1), (397, 1), (398, 1), (399, 2), (400, 2), (401, 1)]\n"
          ]
        }
      ],
      "source": [
        "from gensim import corpora\n",
        "\n",
        "# Create a dictionary from the lemmatized corpus\n",
        "dictionary = corpora.Dictionary(lemmatized_corpus)\n",
        "\n",
        "# Filter out words that appear in less than no_below documents\n",
        "# or more than no_above fraction of total documents\n",
        "# and keep only the most common keep_n words\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
        "\n",
        "# Create a Bag-of-Words corpus\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in lemmatized_corpus]\n",
        "\n",
        "print(\"Number of unique tokens in dictionary:\", len(dictionary))\n",
        "print(\"First 5 entries of the BoW corpus:\")\n",
        "for i, doc in enumerate(bow_corpus[:5]):\n",
        "    print(f\"Document {i}: {doc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9c9119d6",
        "outputId": "7010e2d5-515e-4dd5-8f0d-159d0bc62b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA Topics:\n",
            "Topic: 0\n",
            "Words: 0.027*\"series\" + 0.025*\"time\" + 0.024*\"attention\" + 0.021*\"feature\" + 0.014*\"temporal\" + 0.013*\"prediction\" + 0.012*\"information\" + 0.010*\"based\" + 0.010*\"proposed\" + 0.010*\"forecasting\"\n",
            "\n",
            "Topic: 1\n",
            "Words: 0.049*\"video\" + 0.022*\"frame\" + 0.019*\"motion\" + 0.017*\"flow\" + 0.015*\"action\" + 0.014*\"object\" + 0.012*\"recognition\" + 0.011*\"temporal\" + 0.011*\"based\" + 0.011*\"approach\"\n",
            "\n",
            "Topic: 2\n",
            "Words: 0.023*\"image\" + 0.018*\"generative\" + 0.014*\"face\" + 0.012*\"adversarial\" + 0.011*\"data\" + 0.010*\"user\" + 0.010*\"gan\" + 0.009*\"generation\" + 0.008*\"real\" + 0.008*\"generated\"\n",
            "\n",
            "Topic: 3\n",
            "Words: 0.057*\"image\" + 0.012*\"resolution\" + 0.012*\"depth\" + 0.009*\"based\" + 0.008*\"estimation\" + 0.008*\"segmentation\" + 0.008*\"approach\" + 0.008*\"shape\" + 0.007*\"result\" + 0.007*\"using\"\n",
            "\n",
            "Topic: 4\n",
            "Words: 0.014*\"deep\" + 0.014*\"neural\" + 0.012*\"machine\" + 0.011*\"decision\" + 0.011*\"tree\" + 0.009*\"explanation\" + 0.008*\"prediction\" + 0.007*\"data\" + 0.006*\"paper\" + 0.006*\"analysis\"\n",
            "\n",
            "Topic: 5\n",
            "Words: 0.018*\"algorithm\" + 0.012*\"problem\" + 0.010*\"function\" + 0.010*\"policy\" + 0.009*\"reinforcement\" + 0.008*\"agent\" + 0.007*\"show\" + 0.007*\"based\" + 0.007*\"state\" + 0.006*\"approach\"\n",
            "\n",
            "Topic: 6\n",
            "Words: 0.027*\"point\" + 0.022*\"visual\" + 0.022*\"object\" + 0.020*\"image\" + 0.016*\"task\" + 0.016*\"cloud\" + 0.014*\"text\" + 0.012*\"scene\" + 0.012*\"language\" + 0.009*\"semantic\"\n",
            "\n",
            "Topic: 7\n",
            "Words: 0.028*\"graph\" + 0.024*\"data\" + 0.017*\"task\" + 0.016*\"representation\" + 0.012*\"domain\" + 0.012*\"supervised\" + 0.010*\"training\" + 0.009*\"unsupervised\" + 0.009*\"node\" + 0.009*\"label\"\n",
            "\n",
            "Topic: 8\n",
            "Words: 0.032*\"data\" + 0.030*\"time\" + 0.013*\"series\" + 0.010*\"accuracy\" + 0.010*\"using\" + 0.009*\"system\" + 0.008*\"approach\" + 0.008*\"deep\" + 0.008*\"training\" + 0.008*\"performance\"\n",
            "\n",
            "Topic: 9\n",
            "Words: 0.023*\"feature\" + 0.014*\"attention\" + 0.012*\"image\" + 0.011*\"performance\" + 0.010*\"object\" + 0.010*\"detection\" + 0.010*\"layer\" + 0.009*\"propose\" + 0.009*\"proposed\" + 0.009*\"art\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import LdaModel\n",
        "\n",
        "# Set the number of topics\n",
        "num_topics = 10\n",
        "\n",
        "# Train the LDA model\n",
        "lda_model = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=10, random_state=100)\n",
        "\n",
        "# Print the topics\n",
        "print(\"LDA Topics:\")\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Topic: {idx}\\nWords: {topic}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3cc4e4a1",
        "outputId": "a0a2baf1-3ae1-4783-a0f9-d3d2496690af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    Graph neural networks (GNNs) have been widely ...\n",
            "1    Deep networks and decision forests (such as ra...\n",
            "2    Graph convolutional networks (GCNs) are powerf...\n",
            "3    With the increasing popularity of Graph Neural...\n",
            "4    Machine learning solutions for pattern classif...\n",
            "Name: abstracts, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(f'{path}/arxiv_data_210930-054931.csv')\n",
        "\n",
        "corpus_nmf = df1['abstracts']\n",
        "print(corpus_nmf.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3008151"
      },
      "source": [
        "## Text Preprocessing for NMF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "96b19a9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96f8d0b-1f29-4526-c5c5-3386083c2754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original corpus (first 5):\n",
            "0    Graph neural networks (GNNs) have been widely ...\n",
            "1    Deep networks and decision forests (such as ra...\n",
            "2    Graph convolutional networks (GCNs) are powerf...\n",
            "3    With the increasing popularity of Graph Neural...\n",
            "4    Machine learning solutions for pattern classif...\n",
            "Name: abstracts, dtype: object\n",
            "\n",
            "Cleaned corpus (first 5):\n",
            "0    graph neural networks gnns have been widely us...\n",
            "1    deep networks and decision forests such as ran...\n",
            "2    graph convolutional networks gcns are powerful...\n",
            "3    with the increasing popularity of graph neural...\n",
            "4    machine learning solutions for pattern classif...\n",
            "Name: abstracts, dtype: object\n",
            "\n",
            "Tokenized corpus (first 5):\n",
            "0    [graph, neural, networks, gnns, widely, used, ...\n",
            "1    [deep, networks, decision, forests, random, fo...\n",
            "2    [graph, convolutional, networks, gcns, powerfu...\n",
            "3    [increasing, popularity, graph, neural, networ...\n",
            "4    [machine, learning, solutions, pattern, classi...\n",
            "Name: abstracts, dtype: object\n",
            "\n",
            "Lemmatized corpus (first 5):\n",
            "0    [graph, neural, network, gnns, widely, used, l...\n",
            "1    [deep, network, decision, forest, random, fore...\n",
            "2    [graph, convolutional, network, gcns, powerful...\n",
            "3    [increasing, popularity, graph, neural, networ...\n",
            "4    [machine, learning, solution, pattern, classif...\n",
            "Name: abstracts, dtype: object\n",
            "\n",
            "Preprocessed corpus for NMF (first 5):\n",
            "0    graph neural network gnns widely used learn ve...\n",
            "1    deep network decision forest random forest gra...\n",
            "2    graph convolutional network gcns powerful tool...\n",
            "3    increasing popularity graph neural network gnn...\n",
            "4    machine learning solution pattern classificati...\n",
            "Name: abstracts, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Ensure NLTK data is downloaded (if not already present)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True) # Added to resolve LookupError\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower() # Convert to lowercase\n",
        "    text = re.sub(r'\\d+', '', text) # Remove numbers\n",
        "    text = re.sub(r'[\\W_]+', ' ', text) # Remove punctuation and special characters, replace with space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces and strip leading/trailing spaces\n",
        "    return text\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_and_remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmas = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return lemmas\n",
        "\n",
        "cleaned_corpus_nmf = corpus_nmf.apply(clean_text)\n",
        "tokenized_corpus_nmf = cleaned_corpus_nmf.apply(tokenize_and_remove_stopwords)\n",
        "lemmatized_corpus_nmf = tokenized_corpus_nmf.apply(lemmatize_tokens)\n",
        "\n",
        "# Join the lemmatized tokens back into single strings\n",
        "preprocessed_corpus_nmf = lemmatized_corpus_nmf.apply(lambda x: ' '.join(x))\n",
        "\n",
        "print(\"Original corpus (first 5):\")\n",
        "print(corpus_nmf.head())\n",
        "print(\"\\nCleaned corpus (first 5):\")\n",
        "print(cleaned_corpus_nmf.head())\n",
        "print(\"\\nTokenized corpus (first 5):\")\n",
        "print(tokenized_corpus_nmf.head())\n",
        "print(\"\\nLemmatized corpus (first 5):\")\n",
        "print(lemmatized_corpus_nmf.head())\n",
        "print(\"\\nPreprocessed corpus for NMF (first 5):\")\n",
        "print(preprocessed_corpus_nmf.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bf1faea",
        "outputId": "d49b7d4c-3496-4b90-f414-c7eea6fcf95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document-Term Matrix shape: (56181, 52271)\n",
            "Number of unique terms (vocabulary size): 52271\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Instantiate CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the preprocessed corpus to create the Document-Term Matrix (DTM)\n",
        "dtm = vectorizer.fit_transform(preprocessed_corpus_nmf)\n",
        "\n",
        "print(\"Document-Term Matrix shape:\", dtm.shape)\n",
        "print(\"Number of unique terms (vocabulary size):\", len(vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d1e5a08a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c05406d-e5af-42a8-e7e3-5638b544146b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF model fitted with 10 components.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# Set the number of topics (e.g., 10 topics)\n",
        "num_topics_nmf = 10\n",
        "\n",
        "# Instantiate NMF model with increased max_iter\n",
        "nmf_model = NMF(n_components=num_topics_nmf, random_state=100, init='nndsvda', max_iter=1000)\n",
        "\n",
        "# Fit the NMF model to the DTM\n",
        "nmf_model.fit(dtm)\n",
        "\n",
        "print(f\"NMF model fitted with {num_topics_nmf} components.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9a74ea37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2f4ab3-f37a-4955-e1f9-b396cced25ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NMF Topics:\n",
            "Topic #1:\n",
            "learning task algorithm deep representation policy reinforcement agent problem approach\n",
            "Topic #2:\n",
            "image segmentation resolution color using quality result task adversarial approach\n",
            "Topic #3:\n",
            "graph node representation structure gnns information edge task learning classification\n",
            "Topic #4:\n",
            "model based prediction performance show attention generative trained training time\n",
            "Topic #5:\n",
            "object detection detector scene point dataset box task segmentation performance\n",
            "Topic #6:\n",
            "network neural deep architecture convolutional training layer performance result accuracy\n",
            "Topic #7:\n",
            "data time training domain series real approach set using distribution\n",
            "Topic #8:\n",
            "video frame temporal motion flow action approach time task optical\n",
            "Topic #9:\n",
            "feature attention information representation module point multi local level proposed\n",
            "Topic #10:\n",
            "method based proposed problem point state result propose algorithm art\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic #{topic_idx + 1}:\")\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "    print()\n",
        "\n",
        "n_top_words = 10\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"NMF Topics:\")\n",
        "print_top_words(nmf_model, feature_names, n_top_words)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO172EfrzJTUafltkstyCFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}