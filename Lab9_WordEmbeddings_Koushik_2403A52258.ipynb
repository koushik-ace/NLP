{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrtcG6R1NJAiN7EyWkWrCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik-ace/NLP/blob/main/Lab9_WordEmbeddings_Koushik_2403A52258.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d8a5e63",
        "outputId": "63311df2-2a01-4b77-f0cb-0c9d36c4a49e"
      },
      "source": [
        "!pip install gensim\n",
        "\n",
        "print(\"Re-attempted gensim installation to ensure package availability.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Re-attempted gensim installation to ensure package availability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf5aa5f1",
        "outputId": "b902ce2d-6b8b-42ba-d488-1b599d560700"
      },
      "source": [
        "import gensim.models as models\n",
        "import numpy as np\n",
        "\n",
        "print(\"Libraries gensim.models and numpy imported successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries gensim.models and numpy imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83da4eeb"
      },
      "source": [
        "## Load Word2Vec Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d18820d",
        "outputId": "0d4788f6-b5ae-45ce-9a7a-683468a13c8f"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "print(\"Downloading Word2Vec model (this may take a while)...\")\n",
        "word2vec_model = api.load('word2vec-google-news-300')\n",
        "print(\"Word2Vec model loaded successfully.\")\n",
        "\n",
        "# Verify if a specific word exists in the model's vocabulary\n",
        "word_to_check = 'king'\n",
        "if word2vec_model.has_index_for(word_to_check):\n",
        "    print(f\"'{word_to_check}' exists in the Word2Vec model vocabulary.\")\n",
        "\n",
        "    # Retrieve and display the word vector\n",
        "    king_vector = word2vec_model[word_to_check]\n",
        "    print(f\"Vector for '{word_to_check}':\\n{king_vector[:10]}...\") # Displaying first 10 elements\n",
        "    print(f\"Vector shape: {king_vector.shape}\")\n",
        "else:\n",
        "    print(f\"'{word_to_check}' does not exist in the Word2Vec model vocabulary.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Word2Vec model (this may take a while)...\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Word2Vec model loaded successfully.\n",
            "'king' exists in the Word2Vec model vocabulary.\n",
            "Vector for 'king':\n",
            "[ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]...\n",
            "Vector shape: (300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5c8d232"
      },
      "source": [
        "\n",
        "## Load GloVe Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e44fdea7",
        "outputId": "2dcb8672-d7e3-47dd-92ba-fc2080b3bcd7"
      },
      "source": [
        "print(\"Downloading GloVe model (this may take a while)...\")\n",
        "glove_model = api.load('glove-wiki-gigaword-100')\n",
        "print(\"GloVe model loaded successfully.\")\n",
        "\n",
        "# Verify if a specific word exists in the model's vocabulary\n",
        "word_to_check_glove = 'queen'\n",
        "if glove_model.has_index_for(word_to_check_glove):\n",
        "    print(f\"'{word_to_check_glove}' exists in the GloVe model vocabulary.\")\n",
        "\n",
        "    # Retrieve and display the word vector\n",
        "    queen_vector = glove_model[word_to_check_glove]\n",
        "    print(f\"Vector for '{word_to_check_glove}':\\n{queen_vector[:10]}...\") # Displaying first 10 elements\n",
        "    print(f\"Vector shape: {queen_vector.shape}\")\n",
        "else:\n",
        "    print(f\"'{word_to_check_glove}' does not exist in the GloVe model vocabulary.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading GloVe model (this may take a while)...\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "GloVe model loaded successfully.\n",
            "'queen' exists in the GloVe model vocabulary.\n",
            "Vector for 'queen':\n",
            "[-0.50045 -0.70826  0.55388  0.673    0.22486  0.60281 -0.26194  0.73872\n",
            " -0.65383 -0.21606]...\n",
            "Vector shape: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fbb6fb9"
      },
      "source": [
        "## Word2Vec Word Similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99fe9d16",
        "outputId": "7e945853-653a-4ef7-aa27-71a83afccf0a"
      },
      "source": [
        "print(\"Calculating Word2Vec similarities...\")\n",
        "\n",
        "similarity_king_queen = word2vec_model.similarity('king', 'queen')\n",
        "similarity_man_woman = word2vec_model.similarity('man', 'woman')\n",
        "\n",
        "print(f\"Similarity between 'king' and 'queen': {similarity_king_queen:.4f}\")\n",
        "print(f\"Similarity between 'man' and 'woman': {similarity_man_woman:.4f}\")\n",
        "\n",
        "print(\"Word2Vec similarities calculated and displayed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Word2Vec similarities...\n",
            "Similarity between 'king' and 'queen': 0.6511\n",
            "Similarity between 'man' and 'woman': 0.7664\n",
            "Word2Vec similarities calculated and displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd50efb6"
      },
      "source": [
        "## GloVe Word Similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8d50607",
        "outputId": "f6ea2c52-7260-4969-c8d3-05e36c5d01d3"
      },
      "source": [
        "print(\"Calculating GloVe similarities...\")\n",
        "\n",
        "similarity_glove_king_queen = glove_model.similarity('king', 'queen')\n",
        "similarity_glove_man_woman = glove_model.similarity('man', 'woman')\n",
        "\n",
        "print(f\"Similarity between 'king' and 'queen' (GloVe): {similarity_glove_king_queen:.4f}\")\n",
        "print(f\"Similarity between 'man' and 'woman' (GloVe): {similarity_glove_man_woman:.4f}\")\n",
        "\n",
        "print(\"GloVe similarities calculated and displayed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating GloVe similarities...\n",
            "Similarity between 'king' and 'queen' (GloVe): 0.7508\n",
            "Similarity between 'man' and 'woman' (GloVe): 0.8323\n",
            "GloVe similarities calculated and displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a77c56d0"
      },
      "source": [
        "## Word2Vec Neighbour Words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b354f2fa",
        "outputId": "1af2e45f-e0fc-402f-b8c5-7b78b8d3567e"
      },
      "source": [
        "print(\"Finding most similar words for 'cat'...\")\n",
        "similar_words_cat = word2vec_model.most_similar('cat', topn=5)\n",
        "print(f\"Most similar words to 'cat':\")\n",
        "for word, score in similar_words_cat:\n",
        "    print(f\"- {word}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nFinding most similar words for 'computer'...\")\n",
        "similar_words_computer = word2vec_model.most_similar('computer', topn=5)\n",
        "print(f\"Most similar words to 'computer':\")\n",
        "for word, score in similar_words_computer:\n",
        "    print(f\"- {word}: {score:.4f}\")\n",
        "\n",
        "print(\"Neighboring words for 'cat' and 'computer' found and displayed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding most similar words for 'cat'...\n",
            "Most similar words to 'cat':\n",
            "- cats: 0.8099\n",
            "- dog: 0.7609\n",
            "- kitten: 0.7465\n",
            "- feline: 0.7326\n",
            "- beagle: 0.7151\n",
            "\n",
            "Finding most similar words for 'computer'...\n",
            "Most similar words to 'computer':\n",
            "- computers: 0.7979\n",
            "- laptop: 0.6640\n",
            "- laptop_computer: 0.6549\n",
            "- Computer: 0.6473\n",
            "- com_puter: 0.6082\n",
            "Neighboring words for 'cat' and 'computer' found and displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a5bf2f8"
      },
      "source": [
        "## GloVe Neighbour Words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abf7a28f",
        "outputId": "f4aa4177-e1ec-4034-d01d-04aeb4e68419"
      },
      "source": [
        "print(\"Finding most similar words for 'cat' using GloVe...\")\n",
        "similar_words_cat_glove = glove_model.most_similar('cat', topn=5)\n",
        "print(f\"Most similar words to 'cat' (GloVe):\")\n",
        "for word, score in similar_words_cat_glove:\n",
        "    print(f\"- {word}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nFinding most similar words for 'computer' using GloVe...\")\n",
        "similar_words_computer_glove = glove_model.most_similar('computer', topn=5)\n",
        "print(f\"Most similar words to 'computer' (GloVe):\")\n",
        "for word, score in similar_words_computer_glove:\n",
        "    print(f\"- {word}: {score:.4f}\")\n",
        "\n",
        "print(\"Neighboring words for 'cat' and 'computer' (GloVe) found and displayed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding most similar words for 'cat' using GloVe...\n",
            "Most similar words to 'cat' (GloVe):\n",
            "- dog: 0.8798\n",
            "- rabbit: 0.7424\n",
            "- cats: 0.7323\n",
            "- monkey: 0.7289\n",
            "- pet: 0.7190\n",
            "\n",
            "Finding most similar words for 'computer' using GloVe...\n",
            "Most similar words to 'computer' (GloVe):\n",
            "- computers: 0.8752\n",
            "- software: 0.8373\n",
            "- technology: 0.7642\n",
            "- pc: 0.7366\n",
            "- hardware: 0.7290\n",
            "Neighboring words for 'cat' and 'computer' (GloVe) found and displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a633e0a"
      },
      "source": [
        "## Word2Vec Word Analogy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c10a4ce1",
        "outputId": "a1e1f5d6-4d53-4508-b07b-763900470c2e"
      },
      "source": [
        "print(\"Solving Word2Vec analogy: 'king' - 'man' + 'woman' = ?\")\n",
        "analogy_result = word2vec_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=2)\n",
        "\n",
        "print(\"Result of 'king' - 'man' + 'woman':\")\n",
        "for word, score in analogy_result:\n",
        "    print(f\"- {word}: {score:.4f}\")\n",
        "\n",
        "print(\"Word2Vec analogy solved and displayed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving Word2Vec analogy: 'king' - 'man' + 'woman' = ?\n",
            "Result of 'king' - 'man' + 'woman':\n",
            "- queen: 0.7118\n",
            "- monarch: 0.6190\n",
            "Word2Vec analogy solved and displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "061d6eae"
      },
      "source": [
        "## GloVe Word Analogy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c372280a",
        "outputId": "6f9b08d6-94b5-43a8-b874-d8000fb7c99a"
      },
      "source": [
        "print(\"Solving GloVe analogy: 'king' - 'man' + 'woman' = ?\")\n",
        "analogy_result_glove = glove_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=2)\n",
        "\n",
        "print(\"Result of 'king' - 'man' + 'woman' (GloVe):\")\n",
        "for word, score in analogy_result_glove:\n",
        "    print(f\"- {word}: {score:.4f}\")\n",
        "\n",
        "print(\"GloVe analogy solved and displayed successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving GloVe analogy: 'king' - 'man' + 'woman' = ?\n",
            "Result of 'king' - 'man' + 'woman' (GloVe):\n",
            "- queen: 0.7699\n",
            "- monarch: 0.6843\n",
            "GloVe analogy solved and displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcb3bb6d"
      },
      "source": [
        "## Answers to Word Embeddings Questions\n",
        "\n",
        "### 1. What are word embeddings?\n",
        "Word embeddings are numerical representations of words in a high-dimensional vector space, where words with similar meanings have similar vector representations (i.e., they are closer together in the vector space). These embeddings are learned from large text corpora and capture semantic and syntactic relationships between words.\n",
        "\n",
        "### 2. How are embeddings different from one-hot vectors?\n",
        "\n",
        "*   **One-Hot Vectors:** Represent words as binary vectors where each word has a unique index, and a vector is all zeros except for a single '1' at that word's index. They are high-dimensional (vocabulary size), sparse, and do not capture any semantic relationships between words. The distance between any two one-hot vectors is always the same (e.g., orthogonal).\n",
        "*   **Word Embeddings:** Represent words as dense, low-dimensional real-valued vectors. They are learned in such a way that words with similar meanings are mapped to similar vectors. This allows them to capture semantic relationships (e.g., 'king' and 'queen' vectors are closer than 'king' and 'apple').\n",
        "\n",
        "### 3. What is Word2Vec and what does it learn?\n",
        "Word2Vec is a group of related models that are used to produce word embeddings. It has two main architectures:\n",
        "\n",
        "*   **Continuous Bag-of-Words (CBOW):** Predicts the current word based on its surrounding context words.\n",
        "*   **Skip-gram:** Predicts surrounding context words given the current word.\n",
        "\n",
        "Word2Vec learns **word associations** from a large corpus of text. The idea is that words appearing in similar contexts tend to have similar meanings. It learns to represent words as vectors such that words with similar meanings are close together in the vector space.\n",
        "\n",
        "### 4. What is GloVe and how is it different from Word2Vec?\n",
        "GloVe (Global Vectors for Word Representation) is another popular word embedding model. While Word2Vec is a *predictive* model (predicting words from context or vice versa), GloVe is a *count-based* model. It explicitly incorporates global word-word co-occurrence statistics from the entire corpus to learn word vectors.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "*   **Learning Mechanism:** Word2Vec uses a local context window and trains on predicting context words or target words. GloVe directly models the logarithm of the ratio of co-occurrence probabilities.\n",
        "*   **Information Used:** Word2Vec focuses on local context information. GloVe leverages both local context information (like Word2Vec) and global statistics (like Latent Semantic Analysis).\n",
        "*   **Objective Function:** Word2Vec's objective is to maximize the probability of context words given a target word (or vice-versa). GloVe's objective is to minimize the difference between the dot product of two word vectors and the logarithm of their co-occurrence probability.\n",
        "\n",
        "### 5. Why cosine similarity is used with embeddings?\n",
        "Cosine similarity is commonly used with word embeddings because it measures the cosine of the angle between two non-zero vectors. In the context of embeddings:\n",
        "\n",
        "*   **Direction matters more than magnitude:** Word embeddings are designed so that the *direction* of the vector captures the semantic meaning, while the magnitude (length) is less relevant. Cosine similarity focuses purely on the orientation of the vectors.\n",
        "*   **Captures semantic similarity:** A cosine similarity close to 1 indicates that the vectors are pointing in roughly the same direction, implying high semantic similarity between the words. A value close to -1 indicates dissimilarity, and 0 indicates orthogonality (no relation).\n",
        "*   **Handles varying vector lengths:** Unlike Euclidean distance, which can be heavily influenced by the magnitude of vectors, cosine similarity normalizes vector lengths to 1, making it robust to differences in magnitude.\n",
        "\n",
        "### 6. Give an example of word analogy using vectors.\n",
        "A classic example of word analogy using vectors is the relationship:\n",
        "\n",
        "**\"king - man + woman = queen\"**\n",
        "\n",
        "In vector space, this translates to:\n",
        "\n",
        "$\\vec{king} - \\vec{man} + \\vec{woman} \\approx \\vec{queen}$\n",
        "\n",
        "This demonstrates that the vector difference between `king` and `man` (representing 'royalty' minus 'masculinity') is similar to the vector difference between `queen` and `woman` (representing 'royalty' minus 'femininity'). When you perform this vector arithmetic, the resulting vector is very close to the vector for 'queen'.\n",
        "\n",
        "### 7. Mention two real-life applications of word embeddings\n",
        "\n",
        "1.  **Sentiment Analysis:** Word embeddings allow models to understand the nuanced meaning of words, improving the accuracy of sentiment analysis systems. For example, a model can recognize that words like \"fantastic,\" \"amazing,\" and \"excellent\" are semantically similar and carry positive sentiment, even if they haven't appeared together in training data for that specific task.\n",
        "2.  **Machine Translation:** Word embeddings are crucial in neural machine translation. By representing words in a shared semantic space across different languages, models can better map words and phrases from a source language to a target language, producing more accurate and contextually appropriate translations. They help in understanding the meaning of words irrespective of the language."
      ]
    }
  ]
}